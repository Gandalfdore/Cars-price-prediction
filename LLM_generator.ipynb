{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713b0b56-856c-47a9-af8a-60e9a74a2f0c",
   "metadata": {},
   "source": [
    "### Using LLMs to generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbcaf0-1757-4c99-8f8d-66289b3fc96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Emma', 'Michael', 'Sophia', 'William', 'Olivia', 'James', 'Charlotte'],\n",
    "    'Age': [30, 25, 35, 28, 32, 27, 40, 22, 38, 29],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Philadelphia', 'Phoenix', 'San Antonio', 'San Diego', 'Dallas', 'San Jose']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Convert DataFrame to text format\n",
    "text_data = \"\"\n",
    "for index, row in df.iterrows():\n",
    "    text_data += f\"Name: {row['Name']}, Age: {row['Age']}, City: {row['City']}\\n\"\n",
    "\n",
    "# Write text data to a file\n",
    "with open(\"your_training_data.txt\", \"w\") as file:\n",
    "    file.write(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ebc403-2b9b-404b-b9c4-5e27cee671a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 20:59:35.943866: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-29 20:59:35.943930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-29 20:59:35.946245: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-29 20:59:35.959581: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 20:59:37.451930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/smooth_penguin/anaconda3/envs/koalas/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=1.324582290649414, metrics={'train_runtime': 20.7901, 'train_samples_per_second': 0.24, 'train_steps_per_second': 0.24, 'total_flos': 318960000000.0, 'train_loss': 1.324582290649414, 'epoch': 5.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"  # or any other variant of GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Prepare training data (tokenize and encode)\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"your_training_data.txt\",  # Path to your prepared training data\n",
    "    block_size=125  # Adjust according to your data size\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3836e9-3e64-4ae6-bc0c-59ba76a0ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new rows using the fine-tuned model\n",
    "generated_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Example prompt: \"Name: John, Age: 30, City: New York\"\n",
    "    prompt = f\"Name: {row['Name']}, Age: {row['Age']}, City: {row['City']}\"\n",
    "    \n",
    "    # Generate continuation using the fine-tuned model\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(generated_text)\n",
    "    \n",
    "    # Parse generated text to extract new values\n",
    "    generated_values = generated_text.split(\", \")\n",
    "    new_row = {\n",
    "        'Name': generated_values[0].split(\": \")[1],\n",
    "        'Age': int(generated_values[1].split(\": \")[1]),\n",
    "        'City': generated_values[2].split(\": \")[1]\n",
    "    }\n",
    "    generated_data.append(new_row)\n",
    "\n",
    "# Create a new DataFrame with the generated data\n",
    "new_df = pd.DataFrame(generated_data)\n",
    "print(\"\\nNew DataFrame with Generated Rows:\")\n",
    "print(new_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
